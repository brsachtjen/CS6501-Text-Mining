<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      MP1&mdash; Getting Familiar with Text Processing &middot; CS 6501: Text Mining
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/css/poole.css">
  <link rel="stylesheet" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/css/syntax.css">
  <link rel="stylesheet" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/css/lanyon.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x146" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/UVA_Rotunda_Logo.png">
  <link rel="shortcut icon" sizes="32x32" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/uva_rotunda.jpg">  
</head>


  <body>

    <script type="text/javascript"
      src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script> 
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']],
                         displayMath: [['\\[','\\]'], ['$$','$$']]}});
    </script>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Formula for this course: <br><b>Text Mining = Data Mining + Text Data</b></p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site">Home</a>

    

    
    
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/assignments/">Homework</a>
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/lectures/">Lectures</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/presentation/">Paper Presentation</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/project/">Course Project</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/resources/">Resources</a>
        
      
    
  </nav>

  <div class="sidebar-item">
  	<p>
  		Currently v1.0.0
  	</p>
    <p>
      &copy; 2015. All rights reserved. <a href="http://www.cs.virginia.edu/">CS@UVa</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/~hw5x/Course/Text-Mining-2015-Spring/_site" title="Home">CS 6501: Text Mining</a>
            <small>Spring 2015 &middot; <a href="http://www.cs.virginia.edu/">CS@UVa</a></small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <p>This assignment is designed to help you get familiar with basic document representation and analysis techniques. It  consists of two parts, totaling 100 points:</p>

<ul>
<li><strong>Part 1: <a href="#vsm">Vector Space Model</a></strong> <em>(50 points)</em>: get the basic idea of text processing, e.g., tokenization, stemming, and normalization, construct vector space representation for text documents, TF/IDF weighting, and compute similarity among different text documents;</li>
<li><strong>Part 2: <a href="#slm">Statistical Language Models</a></strong> <em>(50 points)</em>: get the basic idea of statistical language models, including maximum likelihood estimation, smoothing, generate text documents from language models, and language model evaluation.</li>
</ul>

<p>You need to use the CS lab servers to get access to the prepared text documents. Please make sure you have account properly set up on the following three servers:</p>

<ul>
<li>labunix01.cs.virginia.edu</li>
<li>labunix02.cs.virginia.edu</li>
<li>labunix03.cs.virginia.edu</li>
</ul>

<p>If you encountered any technique difficulty in accessing the above servers, e.g., lose of data, software install requirement, or out of disk space, you should immediately send an email to <a href="root@cs.virginia.edu">root@cs.virginia.edu</a> for help.</p>

<h1>Data Set</h1>

<p>The instructor has prepared a medium size collection of Yelp restaurant reviews (<strong>14,083</strong> files for training and <strong>4188</strong> for testing). The data set is located at </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;/home/hw5x/TextMining/MP1/data/Yelp&quot; 
</code></pre></div>
<p>on the above CS lab servers. All of you should already have the read authorization to this folder.</p>

<p>The files are named and organized in the following manner:</p>

<ol>
<li>Each file contains all the review documents for a specific business on Yelp, and it is named by its unique ID on Yelp, e.g., <em>FAhx3UZtXvqNiEAd-GNruQ.json</em>;</li>
<li><p>All the files are in json format. Each json file contains a json array of reviews (&#39;Reviews&#39;) and a json object about the information of the restaurant (&#39;RestaurantInfo&#39;).              </p>

<p>2.1. The json object for <strong>user review</strong> is defined as follows: </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{          
    &#39;Author&#39;:&#39;author name (string)&#39;,
    &#39;ReviewID&#39;:&#39;unique review id (string)&#39;,  
    &#39;Overall&#39;:&#39;numerical rating of the review (float)&#39;,
    &#39;Content&#39;:&#39;review text content (string)&#39;,   
    &#39;Date&#39;:&#39;date when the review was published&#39;,   
    &#39;Author_Location&#39;:&#39;author&#39;s registered location&#39;  
} 
</code></pre></div>
<p>2.2 The json object for <strong>restaurant info</strong> is defined as follows:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{                
    &#39;RestaurantID&#39;:&#39;unique business id in Yelp (string)&#39;,    
    &#39;Name&#39;:&#39;name of the business (string)&#39;,      
    &#39;Price&#39;:&#39;Yelp defined price range (string)&#39;,    
    &#39;RestaurantURL&#39;:&#39;actual URL to the business page on Yelp (string)&#39;,   
    &#39;Longitude&#39;:&#39;longitude of the business (double)&#39;,              
    &#39;Latitude&#39;:&#39;latitude of the business (double)&#39;,              
    &#39;Address&#39;:&#39;address of the business (string)&#39;,       
    &#39;ImgURL&#39;:&#39;URL to the business&#39;s image on Yelp (string)&#39;     
} 
</code></pre></div></li>
</ol>

<p><strong>WARNING</strong>: some collected json files might not strictly follow the above json object definitions, e.g., some fields are missing or empty. As a result, properly handling the exceptions in json parsing is necessary.</p>

<h1>Sample implementation</h1>

<p>A sample Java project has been provided along with this assignment for demonstration purpose. It includes sample code for loading JSON files, tokenization with OpenNLP and stemming with Snowball Stemmer. </p>

<p>It is recommended for you to follow this sample implementation to finish this assignment. It is also allowed to use Python or any other programming language for this assignment, if you are more confident with them. However, no sample implementation will be provided (some Python package usage examples are provided below for your reference). </p>

<h1><a name="preparation"></a>Preparation: Basic Text Processing Techniques</h1>

<h2>Terminologies</h2>

<p>Before describing the specifications of this assignment, several terminologies that will be repeatedly used below  are defined here:</p>

<ul>
<li><strong>Document</strong>: it refers to each individual Yelp review document contained in the json file. Therefore, one json file might contain multiple review documents.<br></li>
<li><strong>Restaurant</strong>: it refers to a specific restaurant entity contained in the given review data set. It is uniquely identified by the corresponding Yelp ID; and one json for one restaurant.<br></li>
<li><strong>DF/IDF/TF/TTF/Cosine similarity</strong>: the definitions for those metrics strictly follow those on our lecture slides, unless specifically defined below.</li>
</ul>

<p>Next, let&#39;s go over several important concepts and techniques for basic text analysis.</p>

<h2>Tokenization</h2>

<p>Tokenization is the process that one breaks a stream of text into meaningful units. Simple tokenizatoin can be achieved by <a href="http://en.wikipedia.org/wiki/Regular_expression">regular expressions</a>. For example, the follow statement in <a href="http://docs.oracle.com/javase/6/docs/api/java/lang/String.html#split(java.lang.String)">Java split</a> the input string into tokens:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&quot;I&#39;ve practiced for 30 years in pediatrics, and I&#39;ve never seen anything quite like this.&quot;.split(&quot;[\\W]+&quot;)
</code></pre></div>
<p>In this statement, we define the boundary for a token to be any non-word sequence. And the corresponding output of this statement is,</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">*I*, *ve*, *practiced*, *for*, *30*, *years*, *in*, *pediatrics*, *and*, *I*, *ve*, *never*, *seen*, *anything*, *quite*, *like*, *this*
</code></pre></div>
<p>where ** indicate the boundary of a token.</p>

<p>A more advanced solution is the statistic machine learning based approaches. And in this assignment, we will show you how to use the tokenizer in <a href="http://opennlp.apache.org/documentation/1.5.3/manual/opennlp.html#tools.tokenizer">OpenNLP</a> (in Java) and <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.tokenize-module.html">NLTK</a> (in Python) to perform tokenization. The NLTK package has been installed on all three CS lab servers.</p>

<h3>1. Tokenizer in OpenNLP</h3>

<p>The detailed documentation for this tokenizer can be found <a href="http://opennlp.apache.org/documentation/1.5.3/manual/opennlp.html#tools.tokenizer">here</a>. You can download the library <a href="http://www.dsgnwrld.com/am//opennlp/opennlp-1.5.3/apache-opennlp-1.5.3-src.zip">here</a> and the trained model file <a href="http://opennlp.sourceforge.net/models-1.5/">here</a> (please choose the English tokenizer). </p>

<p>Once you have properly load the model from file, tokenization can be simply performed by, </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">String tokens[] = tokenizer.tokenize(&quot;An input sample sentence.&quot;);
</code></pre></div>
<h3>2. Tokenizer in NLTK</h3>

<p>NLTK provides several implementations of <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.tokenize-module.html">tokenization modules</a>, and many of them are actually regular expression based.</p>

<p>The usage of them is the same and very simple,</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&gt;&gt;&gt; import nltk
&gt;&gt;&gt; tokenizer = nltk.tokenize.treebank.TreebankWordTokenizer()
&gt;&gt;&gt; tokenizer.tokenize(&quot;I&#39;ve practiced for 30 years in pediatrics, and I&#39;ve never seen anything quite like this.&quot;)
[&#39;I&#39;, &quot;&#39;ve&quot;, &#39;practiced&#39;, &#39;for&#39;, &#39;30&#39;, &#39;years&#39;, &#39;in&#39;, &#39;pediatrics&#39;, &#39;,&#39;, &#39;and&#39;, &#39;I&#39;, &quot;&#39;ve&quot;, &#39;never&#39;, &#39;seen&#39;, &#39;anything&#39;, &#39;quite&#39;, &#39;like&#39;, &#39;this&#39;, &#39;.&#39;]
</code></pre></div>
<h2>Stemming</h2>

<p>Stemming refers to the process of reducing inflected (or sometimes derived) words to their stem, base or root form. For example, &quot;ladies&quot; would be mapped to &quot;ladi&quot; as a result of stemming (although &quot;lady&quot; would be a more desirable result).</p>

<h3>1. Stemmers in Java</h3>

<p>Unfortunately, OpenNLP does not support stemming function currently. There are several existing implementations of stemmer in Java available, including <a href="http://snowball.tartarus.org/download.php">Snowball Stemmer</a> and <a href="http://tartarus.org/%7Emartin/PorterStemmer/java.txt">Porter Stemmer</a>. The Snowball Stemmer package contains both of these two popularly used stemmers.</p>

<p>The usage of stemmers Snowball package is very simple,</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">SnowballStemmer stemmer = new englishStemmer(); // get an instance of SnowballStemmer for English
stemmer.setCurrent(token); // set the input
stemmer.stem(); //perform stemming
String stem = stemmer.getCurrent(); // get the output
</code></pre></div>
<h3>2. Stemmers in NLTK</h3>

<p>NLTK provides several implementations of <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.stem-module.html">stemming modules</a>, which includes the Porter Stemmer and Snowball Stemmer.</p>

<p>The usage of either stemmer in NLTK is very simple. For example, to use Snowball Stemmer,</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&gt;&gt;&gt; from nltk.stem.snowball import EnglishStemmer # load the stemmer module from NLTK
&gt;&gt;&gt; stemmer = EnglishStemmer() # get an instance of SnowballStemmer for English
&gt;&gt;&gt; stemmer.stem(&#39;ladies&#39;) # call stemmer to stem the input
u&#39;ladi&#39;
</code></pre></div>
<h2>Stopword removal</h2>

<p>In basic text analysis, stopwords are the words that are filtered out before or after processing of natural language text data, based on the assumption that such words do not carry specific semantic meanings. However, there is not one definite list of stopwords that are applicable in all scenarios, and the definition of stopwords are always domain specific. </p>

<p>Here is a popularly used list of stopwords: <a href="http://jmlr.org/papers/volume5/lewis04a/a11-smart-stop-list/english.stop">Smart system&#39;s stopword list</a>. And we will use it as our initial stopword list for this assignment.  </p>

<h2>N-gram</h2>

<p>An N-gram is a contiguous sequence of n items from a given sequence of text or speech. For example the bigram (2-gram) representation of the sentence &quot;Text mining is helpful for everyone.&quot; would be [&quot;text-mining&quot;, &quot;mining-is&quot;, &quot;is-helpful&quot;, &quot;helpful-for&quot;, &quot;for-everyone&quot;].</p>

<p>To generate the N-grams, you simply scan through the list of split tokens and concatenate the consecutive tokens into N-grams. </p>

<h2>Pre-processing</h2>

<p>There are several general steps of pre-processing you need to take to finish this assignment.</p>

<ul>
<li>Tokenization: tokenize the review content of each document into tokens.</li>
<li>Normalization: normalize the tokens from step 1, by removing individual punctuation marks (here is a list of <a href="http://en.wikipedia.org/wiki/Punctuation_of_English">English punctuation marks</a>), converting tokens into lower cases, and recognizing digit numbers, e.g., integers and floats, and map them to a special symbol &quot;NUM&quot;. </li>
<li>Stemming: stem the tokens back to their root form. </li>
</ul>

<h1><a name="vsm"></a>Part1: Vector Space Model (50pts)</h1>

<p>Based on the above pre-processing steps, we are ready to get some statistics about this corpus and represent the documents in vector space.</p>

<h3>1.1 Understand Zipf&#39;s Law (20pts)</h3>

<p>First, let&#39;s validate the Zipf&#39;s law with the provided Yelp review data set. This can be achieved by the following steps:</p>

<ol>
<li>For each token, go over all the review documents containing it  (in both <strong>train</strong> and <strong>test</strong> folder), and accumulate its frequency in those documents, i.e., total term frequency (TTF).</li>
<li>Order the tokens by their TTF in a descending order.</li>
<li>Create a dot plot by treating each word&#39;s rank as x-axis and its TTF as y-axis. Please use log-log scale for this plot.</li>
</ol>

<p><em>Hint: basically, you can maintain a look-up table in memory while you are scanning through the documents, so that you only need to go through the corpus once to get the counts for all the tokens.</em></p>

<p>From the resulting plot, can we find a strong linear relationship between the x and y axes in the log-log scale? If so, what is the slope of this linear relationship? To answer these questions, you can dump the data into excel and use the plot function there. (You can also use some scientific computing packages for curve fitting for this purpose.)          </p>

<p>Then change the counting statistics in the previous experiment from <em>total term frequency (TTF)</em> to <em>document frequency (DF)</em>, and perform the experiment again. According to new curve and corresponding slope and intercept of the linear interpretation, can you conclude which counting statistics, i.e., <em>TTF</em> v.s., <em>DF</em>, fits Zipf&#39;s law better on this data set? Can you give any explanation about why it fits the law better?</p>

<p><strong>What to submit</strong>: </p>

<ol>
<li>Two curves in log-log space generated above, with the corresponding slopes and intercepts of the linear interpretation results;</li>
<li>Your answers and thoughts to the above questions.</li>
</ol>

<h3>1.2 Construct a Controlled Vocabulary (10pts)</h3>

<p>According to the procedure illustrated in our lecture slide, generate all the bigrams based on the resulting tokens from the pre-processing step (<strong>only in the train folder</strong>), and mix those bigrams with the unigrams as our initial controlled vocabulary.</p>

<p>Collect the DF statistics for all the N-grams (i.e., unigram and bigram) in this initial controlled vocabulary (<strong>only in the train folder</strong>), and find out the top 100 N-grams by DF. Compare this list with our initial stopword list and can you find some restaurant review specific stopwords? Merge those top 100 N-grams into the initial stopword list as our final stopword list.</p>

<p>In the meanwhile, filter out the N-grams with DF smaller than 50. All the rest N-grams will be used as our controlled vocabulary.</p>

<p><strong>What to submit</strong>:</p>

<ol>
<li>List of new stopwords you found specific to restaurant reviews.</li>
<li>The size of the resulting controlled vocabulary (i.e., total N-grams in it).</li>
<li>Top 50 and bottom 50 N-grams according to DF in the resulting controlled vocabulary, and their corresponding IDFs (<strong>should be estimated only based on the train folder</strong>).</li>
</ol>

<h3>1.3 Compute similarity between documents (20pts)</h3>

<p>With the above automatically constructed controlled vocabulary, each review document can be represented as a N-gram vector. Specifically, each dimension in this vector space is defined by the mix of unigrams and bigrams defined in the controlled vocabulary; while the weight for each unigram/bigram in a review document is defined by TF-IDF. Specifically, we will use &quot;<strong>Sub-linear TF scaling</strong>&quot; to compute the normalized TF of each unigram/bigram in a review document. Note the IDF statistics should be <strong>only computed based on the train folder</strong>.</p>

<p>Using this document representation to encode all the review documents in the test folder. </p>

<p>Under the folder of &quot;/home/hw5x/TextMining/MP1/data/Yelp&quot;, there is a special json file named &quot;query.json&quot;, which is manually crafted by the instructor. It contains five carefully selected restaurant reviews from and outside the provided corpus. Construct the vector space representations for these five reviews (as what you have done for those review documents in the test folder) and find out the most similar reviews to them from the test folder, where the similarity metric is defined as cosine similarity. </p>

<p><strong>What to submit</strong>:</p>

<ol>
<li>For each of the query document, list the top 3 most similar review documents (including Author, Content and Date) from the test folder and the corresponding cosine similarity.</li>
<li>Without reading the actual content in the &quot;query.json&quot; file, by simply judging from the content of the retrieved most similar review documents, can you tell which type of restaurants are specified in the query.json file (e.g., Indian food or Korean food)?</li>
</ol>

<h1><a name="slm"></a>Part2: Statistical Language Models (50pts)</h1>

<h3>2.1 Maximum likelihood estimation for statistical language models with proper smoothing (20pts)</h3>

<p>Use all the review documents in the <strong>train folder</strong> to estimate a unigram language model $p_u(w)$ and two bigram language models (with different smoothing methods specified below). When estimating the bigram language models, using linear interpolation smoothing and absolute discount smoothing based on the unigram language model $p_u(w)$ to get two different bigram language models accordingly, i.e., $p^L_b(w_i|w_{i-1})$ and $p^A_b(w_i|w_{i-1})$. In linear interpolation smoothing, set the parameter $\lambda=0.9$; and in absolute discount smoothing, set the parameter $\delta=0.1$.</p>

<p>From the resulting two bigram language models, find the top 10 words that are most likely to follow the word &quot;good&quot;, i.e., rank the words in a descending order by $p^L_b(w|\unicode{x201C}good&quot;)$ and $p^A_b(w|\unicode{x201C}good&quot;)$ and output the top 10 words. Are those top 10 words the same from these two bigram language models? Explain your observation.</p>

<p><em>HINT: to reduce space complexity, you do not need to actually maintain a $V\times V$ array to store the counts and probabilities for the bigram language models. You can use a sparse data structure, e.g., hash map, to store the seen words/bigrams, and perform the smoothing on the fly, i.e., evoke some function calls to return the value of $p^L_b(w|\unicode{x201C}good&quot;)$ and $p^A_b(w|\unicode{x201C}good&quot;)$.</em> </p>

<p><strong>What to submit</strong>:</p>

<ol>
<li>The top 10 words selected from the corresponding two bigram language models.</li>
<li>Your explanation of the observations about the top words under those two bigram language models.</li>
</ol>

<h3>2.2 Generate text documents from a language model (15pts)</h3>

<p>Fixing the sentence length to be 15, generate 10 sentences by sampling words from $p_u(w)$, $p^L_b(w_i|w_{i-1})$ and $p^A_b(w_i|w_{i-1})$ respectively.</p>

<p><em>HINT: you can use $p_u(w)$ to generate the first word of a sentence and then sampling from the corresponding bigram language model when generating from $p^L_b(w_i|w_{i-1})$ and $p^A_b(w_i|w_{i-1})$.</em> </p>

<p><strong>What to submit</strong>:</p>

<ol>
<li>The 10 sentences generated from $p_u(w)$, $p^L_b(w_i|w_{i-1})$ and $p^A_b(w_i|w_{i-1})$ accordingly, and the corresponding likelihood given by the used language model.</li>
</ol>

<h3>2.3 Language model evaluation (15pts)</h3>

<p>Compute perplexity of the previously estimated language models, i.e., $p_u(w)$, $p^L_b(w_i|w_{i-1})$ and $p^A_b(w_i|w_{i-1})$, on all the review documents in the <strong>test folder</strong>.</p>

<p>The perplexity metric defined in our lecture slide is for one document (copied below). Follow that definition to compute perplexity for every review document in the test folder and compute the mean and standard deviation of the  resulting perplexities.</p>

<p>$ PP(w_1,w_2,\dots,w_N) = \sqrt^N{\frac{1}{\prod_{i=1}^N p(w_i|w_{i-1},\dots,w_{i-n+1})}} $</p>

<p>where $d=w_1,w_2,\dots,w_N$, i.e., a text sequence from testing document $d$.</p>

<p><em>NOTE: to smooth the unseen words in the test folder, use additive smoothing to smooth the unigram language model $p_u(w)$ by setting the parameter $\delta=0.1$. Then use the smoothed $\hat p_u(w)$ to smooth $p^L_b(w_i|w_{i-1})$ and $p^A_b(w_i|w_{i-1})$.</em></p>

<p><strong>What to submit</strong>:</p>

<ol>
<li>Report the mean and standard deviation of the perplexities for $\hat p_u(w)$, $\hat p^L_b(w_i|w_{i-1})$ and $\hat p^A_b(w_i|w_{i-1})$ on the test folder.<br></li>
<li>Can you conclude which language model predicts the data in test folder better? And why?</li>
</ol>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
