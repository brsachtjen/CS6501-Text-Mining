<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Lectures &middot; CS 6501: Text Mining
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/css/poole.css">
  <link rel="stylesheet" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/css/syntax.css">
  <link rel="stylesheet" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/css/lanyon.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x146" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/UVA_Rotunda_Logo.png">
  <link rel="shortcut icon" sizes="32x32" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/uva_rotunda.jpg">  
</head>


  <body>

    <script type="text/javascript"      
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full">
    </script> 
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']],
                         displayMath: [['\\[','\\]'], ['$$','$$']]}});
    </script>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Formula for this course: <br><b>Text Mining = Data Mining + Text Data</b></p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site">Home</a>

    

    
    
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/assignments/">Homework</a>
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item active" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/lectures/">Lectures</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/presentation/">Paper Presentation</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/project/">Course Project</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/quizzes/">Quizzes</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/~hw5x/Course/Text-Mining-2015-Spring/_site/resources/">Resources</a>
        
      
    
  </nav>

  <div class="sidebar-item">
  	<p>
  		Currently v1.0.0
  	</p>
    <p>
      &copy; 2015. All rights reserved. <a href="http://www.cs.virginia.edu/">CS@UVa</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/~hw5x/Course/Text-Mining-2015-Spring/_site" title="Home">CS 6501: Text Mining</a>
            <small>Spring 2015 &middot; <a href="http://www.cs.virginia.edu/">CS@UVa</a></small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="page">
  <h1 class="page-title">Lectures</h1>
  <h2>Lecture I: <a href="http://en.wikipedia.org/wiki/Text_mining">Course overview</a></h2>

<blockquote>
<p>We will highlight the basic structure and major topics of this course, and go over some logistic issues and course requirements.     </p>
</blockquote>

<ul>
<li><strong>Day 1</strong>: Introduction (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/IntroductionToTextMining.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/IntroductionToTextMining.pdf">PDF</a>; <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/CoursePolicy.pptx">Course Policy</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/CoursePolicy.pdf">PDF</a>)</li>
</ul>

<hr>

<h2>Lecture II: Document Representation</h2>

<blockquote>
<p>We will discuss how to represent the unstructured text documents with appropriate format and structure to support later automated text mining algorithms.</p>
</blockquote>

<ul>
<li><h3><strong>Day 1</strong>: <a href="http://en.wikipedia.org/wiki/Vector_space_model">Vector space model</a> (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/VS%20model.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/VS%20model.pdf">PDF</a>)</h3>

<ul>
<li><em>Salton, Gerard, Anita Wong, and Chung-Shu Yang. &quot;A vector space model for automatic indexing.&quot; Communications of the ACM 18, no. 11 (1975): 613-620.</em> (<a href="http://dl.acm.org/citation.cfm?id=361220">PDF</a>)</li>
<li><em>Salton, Gerard, and Christopher Buckley. &quot;Term-weighting approaches in automatic text retrieval.&quot; Information processing &amp; management 24, no. 5 (1988): 513-523.</em> (<a href="http://www.sciencedirect.com/science/article/pii/0306457388900210">PDF</a>)</li>
<li><em>Raghavan, Vijay V., and SK Michael Wong. &quot;A critical analysis of vector space model for information retrieval.&quot; Journal of the American Society for information Science 37, no. 5 (1986): 279-287.</em> (<a href="http://www.sics.se/%7Ejussi/Artiklar/2008.04.01.ECIR_Glasgow_filament/2007_rejected_SIGIR/filament/refs/raghavan.pdf">PDF</a>)</li>
<li><em>Singhal, Amit, Chris Buckley, and Mandar Mitra. &quot;Pivoted document length normalization.&quot; In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 21-29. ACM, 1996.</em> (<a href="http://dl.acm.org/citation.cfm?id=243206">PDF</a>)</li>
<li><em>Turney, Peter D., and Patrick Pantel. &quot;From frequency to meaning: Vector space models of semantics.&quot; Journal of artificial intelligence research 37, no. 1 (2010): 141-188.</em> (<a href="http://www.aaai.org/Papers/JAIR/Vol37/JAIR-3705.pdf">PDF</a>)<br></li>
<li><em>Sahlgren, Magnus. &quot;The Word-Space Model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces.&quot; (2006).</em> (<a href="http://www.diva-portal.org/smash/record.jsf?pid=diva2:189276">PDF</a>)</li>
<li><em>Erk, Katrin, and Sebastian Pad√≥. &quot;A structured vector space model for word meaning in context.&quot; In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 897-906. Association for Computational Linguistics, 2008.</em> (<a href="http://t3-1.yum2.net/index/nlp.stanford.edu/pubs/structuredVS.pdf">PDF</a>)</li>
<li><em>Zwarts, Joost, and Yoad Winter. &quot;Vector space semantics: A model-theoretic analysis of locative prepositions.&quot; Journal of logic, language and information 9, no. 2 (2000): 169-211.</em> (<a href="http://link.springer.com/article/10.1023/A:1008384416604">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 2</strong>: <a href="http://en.wikipedia.org/wiki/Language_model">Language models</a> (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/Language%20Models.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/Language%20Models.pdf">PDF</a>)</h3>

<ul>
<li><em>Ponte, Jay M., and W. Bruce Croft. &quot;A language modeling approach to information retrieval.&quot; In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, pp. 275-281. ACM, 1998.</em> (<a href="http://dl.acm.org/citation.cfm?id=291008">PDF</a>)</li>
<li><em>Lavrenko, Victor, and W. Bruce Croft. &quot;Relevance based language models.&quot; In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 120-127. ACM, 2001.</em> (<a href="http://dl.acm.org/citation.cfm?id=383972">PDF</a>)</li>
<li><em>Zhai, Chengxiang, and John Lafferty. &quot;A study of smoothing methods for language models applied to ad hoc information retrieval.&quot; In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 334-342. ACM, 2001.</em> (<a href="http://dl.acm.org/citation.cfm?id=384019">PDF</a>)</li>
<li><em>Chen, Stanley F., and Joshua Goodman. &quot;An empirical study of smoothing techniques for language modeling.&quot; In Proceedings of the 34th annual meeting on Association for Computational Linguistics, pp. 310-318. Association for Computational Linguistics, 1996.</em> (<a href="http://dl.acm.org/citation.cfm?id=981904">PDF</a>)</li>
<li><em>Kneser, Reinhard, and Hermann Ney. &quot;Improved backing-off for m-gram language modeling.&quot; In Acoustics, Speech, and Signal Processing, 1995. ICASSP-95., 1995 International Conference on, vol. 1, pp. 181-184. IEEE, 1995.</em> (<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=479394">PDF</a>)</li>
<li><em>Metzler, Donald, and W. Bruce Croft. &quot;A Markov random field model for term dependencies.&quot; In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 472-479. ACM, 2005.</em> (<a href="http://dl.acm.org/citation.cfm?id=1076115">PDF</a>)</li>
<li><em>Brants, Thorsten, Ashok C. Popat, Peng Xu, Franz J. Och, and Jeffrey Dean. &quot;Large language models in machine translation.&quot; In In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. 2007.</em> (<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.324.3653">PDF</a>)</li>
<li><em>Teh, Yee Whye. &quot;A hierarchical Bayesian language model based on Pitman-Yor processes.&quot; In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pp. 985-992. Association for Computational Linguistics, 2006.</em> (<a href="http://dl.acm.org/citation.cfm?id=1220299">PDF</a>)</li>
<li><em>Goodman, Joshua T. &quot;A bit of progress in language modeling.&quot; Computer Speech &amp; Language 15, no. 4 (2001): 403-434.</em> (<a href="http://www.sciencedirect.com/science/article/pii/S0885230801901743">PDF</a>)</li>
</ul></li>
</ul>

<hr>

<h2>Lecture III: <a href="http://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a></h2>

<blockquote>
<p>We will briefly provide an introduction to computational linguistics, from morphology (word formation) and syntax (sentence structure) to semantics (meaning), as the first step to process and analyze text data. Public natural langauge processing (NLP) toolkits will be introduced for you to understand and practice with those techniques. </p>
</blockquote>

<ul>
<li><h3><strong>Day 1</strong>: Get familiar with NLP pipelines (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/IntroductionToNLP.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/IntroductionToNLP.pdf">PDF</a>)</h3>

<ul>
<li><em>Torres-Carrasquillo, Pedro A., Douglas A. Reynolds, and J. R. Deller Jr. &quot;Language identification using Gaussian mixture model tokenization.&quot; In Acoustics, Speech, and Signal Processing (ICASSP), 2002 IEEE International Conference on, vol. 1, pp. I-757. IEEE, 2002.</em> (<a href="http://llwebprod2.ll.mit.edu/mission/communications/publications/publication-files/full_papers/020513_Torres.pdf">PDF</a>)</li>
<li><em>Chung, Tagyoung, and Daniel Gildea. &quot;Unsupervised tokenization for machine translation.&quot; In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, pp. 718-726. Association for Computational Linguistics, 2009.</em> (<a href="http://www.aclweb.org/anthology/D/D09/D09-1075.pdf">PDF</a>)</li>
<li><em>Lovins, Julie B. Development of a stemming algorithm. MIT Information Processing Group, Electronic Systems Laboratory, 1968.</em> (<a href="http://mt-archive.info/MT-1968-Lovins.pdf">PDF</a>)</li>
<li>Porter, Martin. &quot;Snowball: A language for stemming algorithms.&quot; (2001). (<a href="http://snowball.tartarus.org/texts/introduction.html">PDF</a>)<br></li>
</ul></li>
<li><h3><strong>Day 2</strong>: <a href="http://en.wikipedia.org/wiki/Part-of-speech_tagging">Part-of-Speech tagging</a>, <a href="http://en.wikipedia.org/wiki/Shallow_parsing">chunking</a> &amp; <a href="http://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>    (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/POSTagging-SequenceLabeling.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/POSTagging-SequenceLabeling.pdf">PDF</a>)</h3>

<ul>
<li><em>Ratnaparkhi, Adwait. &quot;A maximum entropy model for part-of-speech tagging.&quot; In Proceedings of the conference on empirical methods in natural language processing, vol. 1, pp. 133-142. 1996.</em> (<a href="http://www.ling.helsinki.fi/kit/2011s/clt350/docs/Ratnaparkhi-tagging96.pdf">PDF</a>)</li>
<li><em>Gimpel, Kevin, Nathan Schneider, Brendan O&#39;Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. &quot;Part-of-speech tagging for twitter: Annotation, features, and experiments.&quot; In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pp. 42-47. Association for Computational Linguistics, 2011.</em> (<a href="http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA547371&amp;%3BLocation=U2&amp;%3Bdoc=GetTRDoc.pdf&amp;origin=publication_detail">PDF</a>)</li>
<li><em>Kudo, Taku, and Yuji Matsumoto. &quot;Chunking with support vector machines.&quot; In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, pp. 1-8. Association for Computational Linguistics, 2001.</em> (<a href="http://dl.acm.org/citation.cfm?id=1073361">PDF</a>)</li>
<li><em>Ando, Rie Kubota, and Tong Zhang. &quot;A high-performance semi-supervised learning method for text chunking.&quot; In Proceedings of the 43rd annual meeting on association for computational linguistics, pp. 1-9. Association for Computational Linguistics, 2005.</em> (<a href="http://www.aclweb.org/anthology/P/P05/P05-1.pdf#page=29">PDF</a>)</li>
<li><em>Sha, Fei, and Fernando Pereira. &quot;Shallow parsing with conditional random fields.&quot; In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, pp. 134-141. Association for Computational Linguistics, 2003.</em> (<a href="http://dl.acm.org/citation.cfm?id=1073473">PDF</a>)</li>
<li><em>Collins, Michael. &quot;Ranking algorithms for named-entity extraction: Boosting and the voted perceptron.&quot; In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pp. 489-496. Association for Computational Linguistics, 2002.</em> (<a href="http://dl.acm.org/citation.cfm?id=1073165">PDF</a>)</li>
<li><em>Moschitti, Alessandro. &quot;A study on convolution kernels for shallow semantic parsing.&quot; In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, p. 335. Association for Computational Linguistics, 2004.</em> (<a href="http://dl.acm.org/citation.cfm?id=1218998">PDF</a>)</li>
<li><em>Poon, Hoifung, and Pedro Domingos. &quot;Unsupervised semantic parsing.&quot; In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pp. 1-10. Association for Computational Linguistics, 2009.</em> (<a href="http://dl.acm.org/citation.cfm?id=1699512">PDF</a>)</li>
<li><em>Ritter, Alan, Sam Clark, and Oren Etzioni. &quot;Named entity recognition in tweets: an experimental study.&quot; In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1524-1534. Association for Computational Linguistics, 2011.</em> (<a href="http://dl.acm.org/citation.cfm?id=2145595">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 3</strong>: <a href="http://en.wikipedia.org/wiki/Lexical_semantics">Lexical semantics</a> &amp; <a href="http://en.wikipedia.org/wiki/Word_sense">word senses</a>  (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/LexicalSemanticsWordSenses.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/LexicalSemanticsWordSenses.pdf">PDF</a>)</h3>

<ul>
<li><em>Miller, George A., Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller. &quot;Introduction to wordnet: An on-line lexical database.&quot; International journal of lexicography 3, no. 4 (1990): 235-244.</em> (<a href="http://www.researchgate.net/publication/31441225_Introduction_to_WordNet_An_On-line_Lexical_Database*/file/9c96052a8b7ca401b1.pdf">PDF</a>)</li>
<li><em>Gildea, Daniel, and Daniel Jurafsky. &quot;Automatic labeling of semantic roles.&quot; Computational linguistics 28, no. 3 (2002): 245-288.</em> (<a href="http://ftp.icsi.berkeley.edu/ftp/pub/techreports/2001/tr-01-005.pdf">PDF</a>)</li>
<li><em>Palmer, Martha, Daniel Gildea, and Paul Kingsbury. &quot;The proposition bank: An annotated corpus of semantic roles.&quot; Computational linguistics 31, no. 1 (2005): 71-106.</em> (<a href="http://www.cs.rochester.edu/%7Egildea/palmer-propbank-cl.pdf">PDF</a>)</li>
<li><em>Pedersen, Ted, Siddharth Patwardhan, and Jason Michelizzi. &quot;WordNet:: Similarity: measuring the relatedness of concepts.&quot; In Demonstration Papers at HLT-NAACL 2004, pp. 38-41. Association for Computational Linguistics, 2004.</em> (<a href="http://www.aaai.org/Papers/AAAI/2004/AAAI04-160.pdf">PDF</a>)</li>
<li><em>Yarowsky, David. &quot;Unsupervised word sense disambiguation rivaling supervised methods.&quot; In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, pp. 189-196. Association for Computational Linguistics, 1995.</em> (<a href="http://www.cse.unt.edu/%7Erada/CSCE5330/Papers/Yarowsky.ACL95.pdf">PDF</a>)</li>
<li><em>Ide, Nancy, and Jean V√©ronis. &quot;Introduction to the special issue on word sense disambiguation: the state of the art.&quot; Computational linguistics 24, no. 1 (1998): 2-40.</em> (<a href="http://promethee.philo.ulg.ac.be/engdep1/download/prolog/lexdis/docs/lexdis/otherpap/veronis-ide-wsd.pdf">PDF</a>)</li>
<li><em>Lesk, Michael. &quot;Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone.&quot; In Proceedings of the 5th annual international conference on Systems documentation, pp. 24-26. ACM, 1986.</em> (<a href="http://promethee.philo.ulg.ac.be/engdep1/download/prolog/lexdis/docs/lexdis/otherpap/Lesk%20clean.pdf">PDF</a>)</li>
<li><em>Yarowsky, David. &quot;Unsupervised word sense disambiguation rivaling supervised methods.&quot; In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, pp. 189-196. Association for Computational Linguistics, 1995.</em> (<a href="http://www.cse.unt.edu/%7Erada/CSCE5330/Papers/Yarowsky.ACL95.pdf">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 4</strong>: <a href="http://en.wikipedia.org/wiki/Machine_translation">Machine translation</a> (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/StatisticalMachineTranslation.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/StatisticalMachineTranslation.pdf">PDF</a>)</h3>

<ul>
<li><em>Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. &quot;BLEU: a method for automatic evaluation of machine translation.&quot; In Proceedings of the 40th annual meeting on association for computational linguistics, pp. 311-318. Association for Computational Linguistics, 2002.</em> (<a href="http://www.aclweb.org/anthology/P02-1040.pdf">PDF</a>)</li>
<li><em>Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan et al. &quot;Moses: Open source toolkit for statistical machine translation.&quot; In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pp. 177-180. Association for Computational Linguistics, 2007.</em> (<a href="http://www.aclweb.org/anthology/P/P07/P07-2.pdf#page=193">PDF</a>)</li>
<li><em>Och, Franz Josef. &quot;Minimum error rate training in statistical machine translation.&quot; In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pp. 160-167. Association for Computational Linguistics, 2003.</em> (<a href="http://dl.acm.org/citation.cfm?id=1075117">PDF</a>)</li>
<li><em>Brown, Peter F., Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. &quot;The mathematics of statistical machine translation: Parameter estimation.&quot; Computational linguistics 19, no. 2 (1993): 263-311.</em> (<a href="http://dl.acm.org/citation.cfm?id=972474">PDF</a>)</li>
<li><em>Brown, Peter F., John Cocke, Stephen A. Della Pietra, Vincent J. Della Pietra, Fredrick Jelinek, John D. Lafferty, Robert L. Mercer, and Paul S. Roossin. &quot;A statistical approach to machine translation.&quot; Computational linguistics 16, no. 2 (1990): 79-85.</em> (<a href="http://dl.acm.org/citation.cfm?id=92860">PDF</a>)</li>
<li><em>Och, Franz Josef, and Hermann Ney. &quot;Discriminative training and maximum entropy models for statistical machine translation.&quot; In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pp. 295-302. Association for Computational Linguistics, 2002.</em> (<a href="http://www.aclweb.org/anthology/P02-1038.pdf">PDF</a>)<br></li>
</ul></li>
</ul>

<hr>

<h2>Lecture IV: <a href="http://en.wikipedia.org/wiki/Document_classification">Text Categorization</a></h2>

<blockquote>
<p>Document categorization refers to the task of assigning a text document to one or more classes or categories. We will discuss several basic supervised text categorization algorithms.</p>
</blockquote>

<ul>
<li><h3><strong>Day 1</strong>: <a href="http://en.wikipedia.org/wiki/Feature_selection">Feature selection</a> &amp; <a href="http://en.wikipedia.org/wiki/Precision_and_recall">Evaluation</a> (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/TextCategorization.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/TextCategorization.pdf">PDF</a>)</h3>

<ul>
<li><em>Kohavi, Ron, and George H. John. &quot;Wrappers for feature subset selection.&quot; Artificial intelligence 97, no. 1 (1997): 273-324.</em> (<a href="http://www.sciencedirect.com/science/article/pii/S000437029700043X">PDF</a>)</li>
<li><em>Guyon, Isabelle, and Andr√© Elisseeff. &quot;An introduction to variable and feature selection.&quot; The Journal of Machine Learning Research 3 (2003): 1157-1182.</em> (<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/GuyonE03.pdf">PDF</a>)</li>
<li><em>Yang, Yiming, and Jan O. Pedersen. &quot;A comparative study on feature selection in text categorization.&quot; In ICML, vol. 97, pp. 412-420. 1997.</em> (<a href="http://casa.disi.unitn.it/%7Emoschitt/Projects/yang97comparative.pdf">PDF</a>)</li>
<li><em>Kira, Kenji, and Larry A. Rendell. &quot;The feature selection problem: Traditional methods and a new algorithm.&quot; In AAAI, pp. 129-134. 1992.</em> (<a href="http://www.aaai.org/Papers/AAAI/1992/AAAI92-020.pdf">PDF</a>)</li>
<li><em>Forman, George. &quot;An extensive empirical study of feature selection metrics for text classification.&quot; The Journal of machine learning research 3 (2003): 1289-1305.</em> (<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/Forman03.pdf">PDF</a>)</li>
<li><em>Rogati, Monica, and Yiming Yang. &quot;High-performing feature selection for text classification.&quot; In Proceedings of the eleventh international conference on Information and knowledge management, pp. 659-661. ACM, 2002.</em> (<a href="http://www.cs.cmu.edu/afs/cs/Web/People/dgovinda/pdf/rogati-cikm02.pdf">PDF</a>)</li>
<li><em>Liu, Huan, and Lei Yu. &quot;Toward integrating feature selection algorithms for classification and clustering.&quot; Knowledge and Data Engineering, IEEE Transactions on 17, no. 4 (2005): 491-502.</em> (<a href="http://web.iaincirebon.ac.id/ebook/luke/ieeeexplore/Knowledge_and_Data_Engineering/Toward_integrating_feature_selection_algorithms_for_classification_and_clustering-m7s.pdf">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 2</strong>: <a href="http://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes</a> &amp; <a href="http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">kNN</a> (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/kNN%20&amp;%20Na%C3%AFve%20Bayes.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/kNN%20&amp;%20Naive%20Bayes.pdf">PDF</a>)</h3>

<ul>
<li><em>Zhang, Harry. &quot;The optimality of naive Bayes.&quot; AA 1, no. 2 (2004): 3.</em> (<a href="http://www.aaai.org/Papers/FLAIRS/2004/Flairs04-097.pdf">PDF</a>)</li>
<li><em>Rish, Irina. &quot;An empirical study of the naive Bayes classifier.&quot; In IJCAI 2001 workshop on empirical methods in artificial intelligence, vol. 3, no. 22, pp. 41-46. 2001.</em> (<a href="http://www.researchgate.net/publication/228845263_An_empirical_study_of_the_naive_Bayes_classifier/file/60b7d52dc3ccd8d692.pdf">PDF</a>)</li>
<li><em>Eyheramendy, Susana, David D. Lewis, and David Madigan. &quot;On the naive bayes model for text categorization.&quot; (2003).</em> (<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.4949">PDF</a>)</li>
<li><em>Peng, Fuchun, Dale Schuurmans, and Shaojun Wang. &quot;Augmenting naive bayes classifiers with statistical language models.&quot; Information Retrieval 7, no. 3-4 (2004): 317-345.</em> (<a href="http://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1090&amp;context=cs_faculty_pubs">PDF</a>)</li>
<li><em>Yang, Yiming, and Xin Liu. &quot;A re-examination of text categorization methods.&quot; In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pp. 42-49. ACM, 1999.</em> (<a href="http://dl.acm.org/citation.cfm?id=312647">PDF</a>)</li>
<li><em>Yang, Yiming. &quot;An evaluation of statistical approaches to text categorization.&quot; Information retrieval 1, no. 1-2 (1999): 69-90.</em> (<a href="http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA327980">PDF</a>)</li>
<li><em>Beyer, Kevin, Jonathan Goldstein, Raghu Ramakrishnan, and Uri Shaft. &quot;When is ‚Äúnearest neighbor‚Äù meaningful?.&quot; In Database Theory‚ÄîICDT‚Äô99, pp. 217-235. Springer Berlin Heidelberg, 1999.</em> (<a href="http://research.cs.wisc.edu/techreports/1998/TR1377.pdf">PDF</a>)</li>
<li><em>Keller, James M., Michael R. Gray, and James A. Givens. &quot;A fuzzy k-nearest neighbor algorithm.&quot; Systems, Man and Cybernetics, IEEE Transactions on 4 (1985): 580-585.</em> (<a href="http://www.cs.missouri.edu/%7Eskubicm/8820/FuzzyKNN.pdf">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 3</strong>: <a href="http://en.wikipedia.org/wiki/Logistic_regression">Logistic regression</a> (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/Logistic%20Regression.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/Logistic%20Regression.pdf">PDF</a>)</h3>

<ul>
<li><em>Jordan, A. &quot;On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes.&quot; Advances in neural information processing systems 14 (2002): 841.</em> (<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/nips02-AA28.pdf">PDF</a>)</li>
<li><em>Hosmer Jr, David W., and Stanley Lemeshow. Applied logistic regression. John Wiley &amp; Sons, 2004.</em> (<a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=Po0RLQ7USIMC&amp;oi=fnd&amp;pg=PR5&amp;dq=logistic+regression&amp;ots=Do50mh_mGR&amp;sig=AvM9kLUFDIxicYsbEp4FKdbzOyg#v=onepage&amp;q=logistic%20regression&amp;f=false">PDF</a>)</li>
<li><em>Peduzzi, Peter, John Concato, Elizabeth Kemper, Theodore R. Holford, and Alvan R. Feinstein. &quot;A simulation study of the number of events per variable in logistic regression analysis.&quot; Journal of clinical epidemiology 49, no. 12 (1996): 1373-1379.</em> (<a href="http://www.sciencedirect.com/science/article/pii/S0895435696002363">PDF</a>)</li>
<li><em>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. &quot;Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors).&quot; The annals of statistics 28, no. 2 (2000): 337-407.</em> (<a href="http://projecteuclid.org/download/pdf_1/euclid.aos/1016218223">PDF</a>)</li>
<li><em>Genkin, Alexander, David D. Lewis, and David Madigan. &quot;Large-scale Bayesian logistic regression for text categorization.&quot; Technometrics 49, no. 3 (2007): 291-304.</em> (<a href="http://www.stat.columbia.edu/%7Emadigan/PAPERS/techno.pdf">PDF</a>)</li>
<li><em>Lewis, David D., and William A. Gale. &quot;A sequential algorithm for training text classifiers.&quot; In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 3-12. Springer-Verlag New York, Inc., 1994.</em> (<a href="http://arxiv.org/pdf/cmp-lg/9407020">PDF</a>)</li>
<li><em>Zhang, Jian, Rong Jin, Yiming Yang, and Alexander G. Hauptmann. &quot;Modified logistic regression: An approximation to svm and its applications in large-scale text categorization.&quot; In ICML, pp. 888-895. 2003.</em> (<a href="http://www.aaai.org/Papers/ICML/2003/ICML03-115.pdf">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 4</strong>: <a href="http://en.wikipedia.org/wiki/Support_vector_machine">Support vector machine</a> (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/svm.pptx">Slides</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/svm.pdf">PDF</a>)</h3>

<ul>
<li><em>Suykens, Johan AK, and Joos Vandewalle. &quot;Least squares support vector machine classifiers.&quot; Neural processing letters 9, no. 3 (1999): 293-300.</em> (<a href="http://link.springer.com/article/10.1023/A:1018628609742">PDF</a>)</li>
<li><em>Joachims, Thorsten. &quot;Training linear SVMs in linear time.&quot; In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 217-226. ACM, 2006.</em> (<a href="http://dl.acm.org/citation.cfm?id=1150429">PDF</a>)</li>
<li><em>Nigam, Kamal, Andrew Kachites McCallum, Sebastian Thrun, and Tom Mitchell. &quot;Text classification from labeled and unlabeled documents using EM.&quot; Machine learning 39, no. 2-3 (2000): 103-134.</em> (<a href="http://link.springer.com/article/10.1023/A:1007692713085">PDF</a>)</li>
<li><em>Lodhi, Huma, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and Chris Watkins. &quot;Text classification using string kernels.&quot; The Journal of Machine Learning Research 2 (2002): 419-444.</em> (<a href="http://dl.acm.org/citation.cfm?id=944799">PDF</a>)</li>
<li><em>Sriram, Bharath, Dave Fuhry, Engin Demir, Hakan Ferhatosmanoglu, and Murat Demirbas. &quot;Short text classification in twitter to improve information filtering.&quot; In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, pp. 841-842. ACM, 2010.</em> (<a href="http://dl.acm.org/citation.cfm?id=1835643">PDF</a>)<br></li>
<li><em>Tong, Simon, and Daphne Koller. &quot;Support vector machine active learning with applications to text classification.&quot; The Journal of Machine Learning Research 2 (2002): 45-66.</em> (<a href="http://dl.acm.org/citation.cfm?id=944793">PDF</a>)</li>
<li><em>Joachims, Thorsten. &quot;Transductive inference for text classification using support vector machines.&quot; In ICML, vol. 99, pp. 200-209. 1999.</em> (<a href="http://www1.cs.columbia.edu/%7Edplewis/candidacy/joachims99transductive.pdf">PDF</a>)</li>
<li><em>Fan, Rong-En, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. &quot;LIBLINEAR: A library for large linear classification.&quot; The Journal of Machine Learning Research 9 (2008): 1871-1874.</em> (<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/fan08a.pdf">PDF</a>)</li>
</ul></li>
</ul>

<hr>

<h2>Lecture V: <a href="http://en.wikipedia.org/wiki/Document_clustering">Text Clustering</a></h2>

<blockquote>
<p>Text clustering refers to the task of identifying the clustering structure of a corpus of text documents and assigning documents to the identified cluster(s). We will discuss two typical types of clustering algorithms, i.e., centroid-based clustering (e.g., k-means clustering) and connectivity-based clustering (a.k.a., hierarchical clustering).                   </p>
</blockquote>

<ul>
<li><h3><strong>Day 1</strong>: <a href="http://en.wikipedia.org/wiki/K-means_clustering">k-Means</a> &amp; <a href="http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">Expectation Maximization</a> - flat structure clustering      (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/TextClustering.pptx">Slides for clustering</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/TextClustering.pdf">PDF for clustering</a>) (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/k-means.pptx">Slides for k-means</a>, <a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/PDFs/k-means.pdf">PDF for k-means</a>)</h3>

<ul>
<li><em>Liu, Tao, Shengping Liu, Zheng Chen, and Wei-Ying Ma. &quot;An evaluation on feature selection for text clustering.&quot; In ICML, vol. 3, pp. 488-495. 2003.</em> (<a href="http://www.aaai.org/Papers/ICML/2003/ICML03-065.pdf">PDF</a>)</li>
<li><em>Hartigan, John A., and Manchek A. Wong. &quot;Algorithm AS 136: A k-means clustering algorithm.&quot; Applied statistics (1979): 100-108.</em> (<a href="http://www.labri.fr/perso/bpinaud/userfiles/downloads/hartigan_1979_kmeans.pdf">PDF</a>)</li>
<li><em>Wagstaff, Kiri, Claire Cardie, Seth Rogers, and Stefan Schr√∂dl. &quot;Constrained k-means clustering with background knowledge.&quot; In ICML, vol. 1, pp. 577-584. 2001.</em> (<a href="https://web.cse.msu.edu/%7Ecse802/notes/ConstrainedKmeans.pdf">PDF</a>)<br></li>
<li><em>Kanungo, Tapas, David M. Mount, Nathan S. Netanyahu, Christine D. Piatko, Ruth Silverman, and Angela Y. Wu. &quot;An efficient k-means clustering algorithm: Analysis and implementation.&quot; Pattern Analysis and Machine Intelligence, IEEE Transactions on 24, no. 7 (2002): 881-892.</em> (<a href="http://surface.syr.edu/cgi/viewcontent.cgi?article=1042&amp;context=eecs">PDF</a>)<br></li>
<li><em>Jain, Anil K. &quot;Data clustering: 50 years beyond K-means.&quot; Pattern Recognition Letters 31, no. 8 (2010): 651-666.</em> (<a href="http://www.cse.msu.edu/biometrics/Publications/Clustering/JainClustering_PRL10.pdf">PDF</a>)</li>
<li><em>Zamir, Oren, and Oren Etzioni. &quot;Web document clustering: A feasibility demonstration.&quot; In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, pp. 46-54. ACM, 1998.</em> (<a href="http://dl.acm.org/citation.cfm?id=290956">PDF</a>)</li>
<li><em>Dhillon, Inderjit S., and Dharmendra S. Modha. &quot;Concept decompositions for large sparse text data using clustering.&quot; Machine learning 42, no. 1-2 (2001): 143-175.</em> (<a href="http://www.cs.utexas.edu/users/inderjit/public_papers/concept_mlj.pdf">PDF</a>)</li>
<li><em>Dempster, Arthur P., Nan M. Laird, and Donald B. Rubin. &quot;Maximum likelihood from incomplete data via the EM algorithm.&quot; Journal of the Royal Statistical Society. Series B (Methodological) (1977): 1-38.</em> (<a href="http://www.jstor.org/stable/2984875">PDF</a>)</li>
<li><em>On the convergence properties of the EM algorithm</em> (<a href="http://www.jstor.org/stable/2240463">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 2</strong>: <a href="http://en.wikipedia.org/wiki/Hierarchical_clustering">Agglomerative clustering</a> - hierarchical structure clustering</h3>

<ul>
<li><em>Steinbach, Michael, George Karypis, and Vipin Kumar. &quot;A comparison of document clustering techniques.&quot; In KDD workshop on text mining, vol. 400, no. 1, pp. 525-526. 2000.</em> (<a href="https://wwws.cs.umn.edu/tech_reports_upload/tr2000/00-034.ps">PDF</a>)</li>
<li><em>Hotho, Andreas, Alexander Maedche, and Steffen Staab. &quot;Ontology-based text document clustering.&quot; KI 16, no. 4 (2002): 48-54.</em> (<a href="http://pdf.aminer.org/000/386/677/ontology_based_text_document_clustering.pdf">PDF</a>)</li>
<li><em>Karypis, George, Eui-Hong Han, and Vipin Kumar. &quot;Chameleon: Hierarchical clustering using dynamic modeling.&quot; Computer 32, no. 8 (1999): 68-75.</em> (<a href="http://glaros.dtc.umn.edu/gkhome/fetch/papers/chameleon.pdf">PDF</a>)</li>
<li><em>Navarro, Julio F., Carlos S. Frenk, and Simon DM White. &quot;A Universal density profile from hierarchical clustering.&quot; The Astrophysical Journal 490, no. 2 (1997): 493.</em> (<a href="http://arxiv.org/pdf/astro-ph/9611107">PDF</a>)</li>
<li><em>Zhao, Ying, and George Karypis. &quot;Evaluation of hierarchical clustering algorithms for document datasets.&quot; In Proceedings of the eleventh international conference on Information and knowledge management, pp. 515-524. ACM, 2002.</em> (<a href="http://dl.acm.org/citation.cfm?id=584877">PDF</a>)</li>
<li><em>Fung, Benjamin CM, Ke Wang, and Martin Ester. &quot;Hierarchical document clustering using frequent itemsets.&quot; In SDM, vol. 3, pp. 59-70. 2003.</em> (<a href="http://epubs.siam.org/doi/abs/10.1137/1.9781611972733.6">PDF</a>)</li>
<li><em>Willett, Peter. &quot;Recent trends in hierarchic document clustering: a critical review.&quot; Information Processing &amp; Management 24, no. 5 (1988): 577-597.</em> (<a href="http://www.sciencedirect.com/science/article/pii/0306457388900271">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 3</strong>: Word clustering</h3>

<ul>
<li><em>Deerwester, Scott C., Susan T. Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. &quot;Indexing by latent semantic analysis.&quot; JASIS 41, no. 6 (1990): 391-407.</em> (<a href="http://www.cob.unt.edu/itds/faculty/evangelopoulos/dsci5910/LSA_Deerwester1990.pdf">PDF</a>)</li>
<li><em>Baker, L. Douglas, and Andrew Kachites McCallum. &quot;Distributional clustering of words for text classification.&quot; In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, pp. 96-103. ACM, 1998.</em> (<a href="http://dl.acm.org/citation.cfm?id=290970">PDF</a>)</li>
<li><em>Bengio, Yoshua, Holger Schwenk, Jean-S√©bastien Sen√©cal, Fr√©deric Morin, and Jean-Luc Gauvain. &quot;Neural probabilistic language models.&quot; In Innovations in Machine Learning, pp. 137-186. Springer Berlin Heidelberg, 2006.</em> (<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/BengioDVJ03.pdf">PDF</a>)</li>
<li><em>Bekkerman, Ron, Ran El-Yaniv, Naftali Tishby, and Yoad Winter. &quot;Distributional word clusters vs. words for text categorization.&quot; The Journal of Machine Learning Research 3 (2003): 1183-1208.</em> (<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/BekkermanETW03.pdf">PDF</a>)</li>
<li><em>Curran, James Richard. &quot;From distributional to semantic similarity.&quot; (2004).</em> (<a href="https://www.era.lib.ed.ac.uk/handle/1842/563">PDF</a>)</li>
<li><em>Lin, Dekang. &quot;Automatic retrieval and clustering of similar words.&quot; In Proceedings of the 17th international conference on Computational linguistics-Volume 2, pp. 768-774. Association for Computational Linguistics, 1998.</em> (<a href="http://www.aclweb.org/anthology/P/P98/P98-2127.pdf">PDF</a>)</li>
<li><em>Pereira, Fernando, Naftali Tishby, and Lillian Lee. &quot;Distributional clustering of English words.&quot; In Proceedings of the 31st annual meeting on Association for Computational Linguistics, pp. 183-190. Association for Computational Linguistics, 1993.</em> (<a href="http://pdf.aminer.org/000/346/498/probability_table_compression_using_distributional_clustering_for_scanning_n_tuple.pdf">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 4</strong>: Other clustering algorithms</h3>

<ul>
<li><em>Larsen, Bjornar, and Chinatsu Aone. &quot;Fast and effective text mining using linear-time document clustering.&quot; In Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 16-22. ACM, 1999.</em> (<a href="http://dl.acm.org/citation.cfm?id=312186">PDF</a>)</li>
<li><em>Basu, Sugato, Mikhail Bilenko, and Raymond J. Mooney. &quot;A probabilistic framework for semi-supervised clustering.&quot; In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 59-68. ACM, 2004.</em> (<a href="http://dl.acm.org/citation.cfm?id=1014062">PDF</a>)</li>
<li><em>Xu, Wei, Xin Liu, and Yihong Gong. &quot;Document clustering based on non-negative matrix factorization.&quot; In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pp. 267-273. ACM, 2003.</em> (<a href="http://dl.acm.org/citation.cfm?id=860485">PDF</a>)</li>
<li><em>Dhillon, Inderjit S., Yuqiang Guan, and Brian Kulis. &quot;Kernel k-means: spectral clustering and normalized cuts.&quot; In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 551-556. ACM, 2004.</em> (<a href="http://dl.acm.org/citation.cfm?id=1014118">PDF</a>)</li>
<li><em>Ng, Andrew Y., Michael I. Jordan, and Yair Weiss. &quot;On spectral clustering: Analysis and an algorithm.&quot; Advances in neural information processing systems 2 (2002): 849-856.</em> (<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/nips02-AA35.pdf">PDF</a>)</li>
<li><em>Dhillon, Inderjit S. &quot;Co-clustering documents and words using bipartite spectral graph partitioning.&quot; In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 269-274. ACM, 2001.</em> (<a href="http://dl.acm.org/citation.cfm?id=502550">PDF</a>)<br></li>
<li><em>Cai, Deng, Xiaofei He, and Jiawei Han. &quot;Document clustering using locality preserving indexing.&quot; Knowledge and Data Engineering, IEEE Transactions on 17, no. 12 (2005): 1624-1637.</em> (<a href="http://mall.psy.ohio-state.edu/LexicalSemantics/CaiHeHan05.pdf">PDF</a>)<br></li>
</ul></li>
</ul>

<hr>

<h2>Lecture VI: <a href="http://en.wikipedia.org/wiki/Topic_model">Topic Models</a></h2>

<blockquote>
<p>Topic models are a suite of algorithms that uncover the hidden thematic structure in document collections. We will introduce the general idea of topic modeling, two basic topic models, i.e., Probabilistic Latent Semantic Indexing (pLSI) and Latent Dirichlet Allocation (LDA), and their variants for different application scenarios, including classification, imagine annotation, collaborative filtering, and hierarchical topical structure modeling.</p>
</blockquote>

<ul>
<li><h3><strong>Day 1</strong>: Topic models I (<a href="/%7Ehw5x/Course/Text-Mining-2015-Spring/_site/docs/topic%20models.pptx">slides</a>)</h3>

<ul>
<li><em>Hofmann, Thomas. &quot;Probabilistic latent semantic analysis.&quot; In Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence, pp. 289-296. Morgan Kaufmann Publishers Inc., 1999.</em> (<a href="http://dl.acm.org/citation.cfm?id=2073829">PDF</a>)</li>
<li><em>Blei, David M., Andrew Y. Ng, and Michael I. Jordan. &quot;Latent dirichlet allocation.&quot; the Journal of machine Learning research 3 (2003): 993-1022.</em> (<a href="http://dl.acm.org/citation.cfm?id=944937">PDF</a>)<br></li>
<li><em>Blei, David M., and John D. Lafferty. &quot;Dynamic topic models.&quot; In Proceedings of the 23rd international conference on Machine learning, pp. 113-120. ACM, 2006.</em> (<a href="http://dl.acm.org/citation.cfm?id=1143859">PDF</a>)</li>
<li><em>Rosen-Zvi, Michal, Thomas Griffiths, Mark Steyvers, and Padhraic Smyth. &quot;The author-topic model for authors and documents.&quot; In Proceedings of the 20th conference on Uncertainty in artificial intelligence, pp. 487-494. AUAI Press, 2004.</em> (<a href="http://dl.acm.org/citation.cfm?id=1036902">PDF</a>)</li>
<li><em>Mcauliffe, Jon D., and David M. Blei. &quot;Supervised topic models.&quot; In Advances in neural information processing systems, pp. 121-128. 2008.</em> (<a href="http://papers.nips.cc/paper/3328-supervised-topic-models">PDF</a>)</li>
<li><em>Wei, Xing, and W. Bruce Croft. &quot;LDA-based document models for ad-hoc retrieval.&quot; In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 178-185. ACM, 2006.</em> (<a href="http://dl.acm.org/citation.cfm?id=1148204">PDF</a>)</li>
<li><em>Blei, David M., and Michael I. Jordan. &quot;Modeling annotated data.&quot; In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pp. 127-134. ACM, 2003.</em> (<a href="http://dl.acm.org/citation.cfm?id=860460">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 2</strong>: Topic models II</h3>

<ul>
<li><em>Tang, Jian, Zhaoshi Meng, Xuanlong Nguyen, Qiaozhu Mei, and Ming Zhang. &quot;Understanding the Limiting Factors of Topic Modeling via Posterior Contraction Analysis.&quot; In Proceedings of The 31st International Conference on Machine Learning, pp. 190-198. 2014.</em> (<a href="http://jmlr.org/proceedings/papers/v32/tang14.html">PDF</a>)</li>
<li>- <em>Teh, Yee Whye, Michael I. Jordan, Matthew J. Beal, and David M. Blei. &quot;Hierarchical dirichlet processes.&quot; Journal of the american statistical association 101, no. 476 (2006).</em> (<a href="http://amstat.tandfonline.com/doi/abs/10.1198/016214506000000302">PDF</a>)</li>
<li><em>Griffiths, D. M. B. T. L., and M. I. J. J. B. Tenenbaum. &quot;Hierarchical topic models and the nested Chinese restaurant process.&quot; Advances in neural information processing systems 16 (2004): 17.</em> (<a href="http://books.google.com/books?hl=en&amp;lr=&amp;id=0F-9C7K8fQ8C&amp;oi=fnd&amp;pg=PA17&amp;ots=THDyj_Q72Z&amp;sig=f-PT7LcpFrlHNrJC1Slk2JU4arM">PDF</a>)</li>
<li><em>Li, Wei, and Andrew McCallum. &quot;Pachinko allocation: DAG-structured mixture models of topic correlations.&quot; In Proceedings of the 23rd international conference on Machine learning, pp. 577-584. ACM, 2006.</em> (<a href="http://dl.acm.org/citation.cfm?id=1143844.1143917">PDF</a>)<br></li>
<li><em>Wang, Chi, Marina Danilevsky, Nihit Desai, Yinan Zhang, Phuong Nguyen, Thrivikrama Taula, and Jiawei Han. &quot;A phrase mining framework for recursive construction of a topical hierarchy.&quot; In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 437-445. ACM, 2013.</em> (<a href="http://dl.acm.org/citation.cfm?id=2487631">PDF</a>)<br></li>
</ul></li>
</ul>

<hr>

<h2>Lecture VII: <a href="http://en.wikipedia.org/wiki/Social_network_analysis">Social Media and Network Analysis</a></h2>

<blockquote>
<p>We will apply the introduced text mining algorithms on social media and introduce Google&#39;s winning algorithm PageRank. We will also introduce the application of link analysis techniques in social network analysis.</p>
</blockquote>

<ul>
<li><h3><strong>Day 1</strong>: <a href="http://en.wikipedia.org/wiki/PageRank">Pagerank</a> and <a href="http://en.wikipedia.org/wiki/HITS_algorithm">HITS</a></h3>

<ul>
<li><em>Page, Lawrence, Sergey Brin, Rajeev Motwani, and Terry Winograd. &quot;The PageRank citation ranking: Bringing order to the web.&quot; (1999).</em> (<a href="http://ilpubs.stanford.edu:8090/422">PDF</a>)</li>
<li><em>Kleinberg, Jon M. &quot;Authoritative sources in a hyperlinked environment.&quot; Journal of the ACM (JACM) 46, no. 5 (1999): 604-632.</em> (<a href="http://dl.acm.org/citation.cfm?id=324140">PDF</a>)</li>
<li><em>Haveliwala, Taher H. &quot;Topic-sensitive pagerank.&quot; In Proceedings of the 11th international conference on World Wide Web, pp. 517-526. ACM, 2002.</em> (<a href="http://dl.acm.org/citation.cfm?id=511513">PDF</a>)</li>
<li><em>Jeh, Glen, and Jennifer Widom. &quot;Scaling personalized web search.&quot; In Proceedings of the 12th international conference on World Wide Web, pp. 271-279. ACM, 2003.</em> (<a href="http://dl.acm.org/citation.cfm?id=775191">PDF</a>)</li>
<li><em>Jeh, Glen, and Jennifer Widom. &quot;SimRank: a measure of structural-context similarity.&quot; In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 538-543. ACM, 2002.</em> (<a href="http://dl.acm.org/citation.cfm?id=775126">PDF</a>)</li>
<li><em>Erkan, G√ºnes, and Dragomir R. Radev. &quot;LexRank: Graph-based lexical centrality as salience in text summarization.&quot; J. Artif. Intell. Res.(JAIR) 22, no. 1 (2004): 457-479.</em> (<a href="http://www.aaai.org/Papers/JAIR/Vol22/JAIR-2214.pdf">PDF</a>)</li>
<li><em>Wan, Xiaojun, and Jianwu Yang. &quot;Multi-document summarization using cluster-based link analysis.&quot; In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pp. 299-306. ACM, 2008.</em> (<a href="http://dl.acm.org/citation.cfm?id=1390386">PDF</a>)</li>
<li><em>Craswell, Nick, and Martin Szummer. &quot;Random walks on the click graph.&quot; Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2007.</em> (<a href="http://dl.acm.org/citation.cfm?id=1277784">PDF</a>)</li>
<li><em>Richardson, Matthew, Amit Prakash, and Eric Brill. &quot;Beyond PageRank: machine learning for static ranking.&quot; Proceedings of the 15th international conference on World Wide Web. ACM, 2006.</em> (<a href="http://dl.acm.org/citation.cfm?id=1135881">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 2</strong>: <a href="http://en.wikipedia.org/wiki/Social_network_analysis">Social network analysis</a></h3>

<ul>
<li><em>Mislove, Alan, Massimiliano Marcon, Krishna P. Gummadi, Peter Druschel, and Bobby Bhattacharjee. &quot;Measurement and analysis of online social networks.&quot; In Proceedings of the 7th ACM SIGCOMM conference on Internet measurement, pp. 29-42. ACM, 2007.</em> (<a href="http://dl.acm.org/citation.cfm?id=1298311">PDF</a>)</li>
<li><em>Shalizi, Cosma Rohilla, and Andrew C. Thomas. &quot;Homophily and contagion are generically confounded in observational social network studies.&quot; Sociological Methods &amp; Research 40.2 (2011): 211-239.</em> (<a href="http://smr.sagepub.com/content/40/2/211.short">PDF</a>)</li>
<li><em>Java, Akshay, Xiaodan Song, Tim Finin, and Belle Tseng. &quot;Why we twitter: understanding microblogging usage and communities.&quot; In Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network analysis, pp. 56-65. ACM, 2007.</em> (<a href="http://dl.acm.org/citation.cfm?id=1348556">PDF</a>)</li>
<li><em>Kwak, Haewoon, et al. &quot;What is Twitter, a social network or a news media?.&quot; Proceedings of the 19th international conference on World wide web. ACM, 2010.</em> (<a href="http://dl.acm.org/citation.cfm?id=1772751">PDF</a>)</li>
<li><em>Suh, Bongwon, et al. &quot;Want to be retweeted? large scale analytics on factors impacting retweet in twitter network.&quot; Social computing (socialcom), 2010 ieee second international conference on. IEEE, 2010.</em> (<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5590452&amp;tag=1">PDF</a>)</li>
<li><em>Newman, Mark EJ. &quot;Finding community structure in networks using the eigenvectors of matrices.&quot; Physical review E 74, no. 3 (2006): 036104.</em> (<a href="http://journals.aps.org/pre/abstract/10.1103/PhysRevE.74.036104">PDF</a>)</li>
<li><em>Leskovec, Jure, Kevin J. Lang, and Michael Mahoney. &quot;Empirical comparison of algorithms for network community detection.&quot; Proceedings of the 19th international conference on World wide web. ACM, 2010.</em> (<a href="http://dl.acm.org/citation.cfm?id=1772755">PDF</a>)</li>
<li><em>Kempe, David, Jon Kleinberg, and √âva Tardos. &quot;Maximizing the spread of influence through a social network.&quot; Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2003.</em> (<a href="http://dl.acm.org/citation.cfm?id=956769">PDF</a>)<br></li>
<li><em>Chen, Wei, Yajun Wang, and Siyu Yang. &quot;Efficient influence maximization in social networks.&quot; Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2009.</em> (<a href="http://dl.acm.org/citation.cfm?id=1557047">PDF</a>)</li>
</ul></li>
</ul>

<hr>

<h2>Lecture VIII: Text Mining Applications</h2>

<blockquote>
<p>We will introduce some modern text mining applications, including sentiment analysis,  document summarization, recommendation, and document visualization.</p>
</blockquote>

<ul>
<li><h3><strong>Day 1</strong>: <a href="http://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment analysis</a></h3>

<ul>
<li><em>Pang, Bo, and Lillian Lee. &quot;Opinion mining and sentiment analysis.&quot; Foundations and trends in information retrieval 2, no. 1-2 (2008): 1-135.</em> (<a href="http://dl.acm.org/citation.cfm?id=1454712">PDF</a>)</li>
<li><em>Esuli, Andrea, and Fabrizio Sebastiani. &quot;Sentiwordnet: A publicly available lexical resource for opinion mining.&quot; In Proceedings of LREC, vol. 6, pp. 417-422. 2006.</em> (<a href="http://gandalf.aksis.uib.no/lrec2006/pdf/384_pdf.pdf">PDF</a>)</li>
<li><em>Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann. &quot;Recognizing contextual polarity in phrase-level sentiment analysis.&quot; In Proceedings of the conference on human language technology and empirical methods in natural language processing, pp. 347-354. Association for Computational Linguistics, 2005.</em> (<a href="http://dl.acm.org/citation.cfm?id=1220619">PDF</a>)</li>
<li><em>Kim, Soo-Min, and Eduard Hovy. &quot;Determining the sentiment of opinions.&quot; In Proceedings of the 20th international conference on Computational Linguistics, p. 1367. Association for Computational Linguistics, 2004.</em> (<a href="http://dl.acm.org/citation.cfm?id=1220555">PDF</a>)</li>
<li><em>Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. &quot;Thumbs up?: sentiment classification using machine learning techniques.&quot; In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pp. 79-86. Association for Computational Linguistics, 2002.</em> (<a href="http://dl.acm.org/citation.cfm?id=1118704">PDF</a>)</li>
<li><em>Hu, Minqing, and Bing Liu. &quot;Mining and summarizing customer reviews.&quot; In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 168-177. ACM, 2004.</em> (<a href="http://dl.acm.org/citation.cfm?id=1014073">PDF</a>)</li>
<li><em>Dave, Kushal, Steve Lawrence, and David M. Pennock. &quot;Mining the peanut gallery: Opinion extraction and semantic classification of product reviews.&quot; In Proceedings of the 12th international conference on World Wide Web, pp. 519-528. ACM, 2003.</em> (<a href="http://dl.acm.org/citation.cfm?id=775226">PDF</a>)</li>
<li><em>Pang, Bo, and Lillian Lee. &quot;Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.&quot; In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pp. 115-124. Association for Computational Linguistics, 2005.</em> (<a href="http://dl.acm.org/citation.cfm?id=1219855">PDF</a>)</li>
<li><em>Wilson, Theresa, Paul Hoffmann, Swapna Somasundaran, Jason Kessler, Janyce Wiebe, Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth Patwardhan. &quot;OpinionFinder: A system for subjectivity analysis.&quot; In Proceedings of hlt/emnlp on interactive demonstrations, pp. 34-35. Association for Computational Linguistics, 2005.</em> (<a href="http://www.egr.msu.edu/%7Ejchai/EMNLP05/demoabstracts/book.pdf#page=42">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 2</strong>: <a href="http://en.wikipedia.org/wiki/Automatic_summarization">Document summarization</a></h3>

<ul>
<li><em>Barzilay, Regina, Kathleen R. McKeown, and Michael Elhadad. &quot;Information fusion in the context of multi-document summarization.&quot; In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, pp. 550-557. Association for Computational Linguistics, 1999.</em> (<a href="http://dl.acm.org/citation.cfm?id=1034760">PDF</a>)</li>
<li><em>Carbonell, Jaime, and Jade Goldstein. &quot;The use of MMR, diversity-based reranking for reordering documents and producing summaries.&quot; In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, pp. 335-336. ACM, 1998.</em> (<a href="http://dl.acm.org/citation.cfm?id=291025">PDF</a>)</li>
<li><em>Goldstein, Jade, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. &quot;Multi-document summarization by sentence extraction.&quot; In Proceedings of the 2000 NAACL-ANLPWorkshop on Automatic summarization-Volume 4, pp. 40-48. Association for Computational Linguistics, 2000.</em> (<a href="http://dl.acm.org/citation.cfm?id=1117580">PDF</a>)</li>
<li><em>Wan, Xiaojun, Jianwu Yang, and Jianguo Xiao. &quot;Manifold-Ranking Based Topic-Focused Multi-Document Summarization.&quot; In IJCAI, vol. 7, pp. 2903-2908. 2007.</em> (<a href="http://www.aaai.org/Papers/IJCAI/2007/IJCAI07-467.pdf">PDF</a>)</li>
<li><em>Wan, Xiaojun, and Jianwu Yang. &quot;Multi-document summarization using cluster-based link analysis.&quot; In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pp. 299-306. ACM, 2008.</em> (<a href="http://dl.acm.org/citation.cfm?id=1390386">PDF</a>)</li>
<li><em>Mani, Inderjeet, and Eric Bloedorn. &quot;Multi-document summarization by graph search and matching.&quot; arXiv preprint cmp-lg/9712004 (1997).</em> (<a href="http://arxiv.org/pdf/cmp-lg/9712004">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 3</strong>: <a href="http://en.wikipedia.org/wiki/Recommender_system">Recommendation</a></h3>

<ul>
<li><em>Koren, Yehuda, Robert Bell, and Chris Volinsky. &quot;Matrix factorization techniques for recommender systems.&quot; Computer 42, no. 8 (2009): 30-37.</em> (<a href="https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf">PDF</a>)</li>
<li><em>Breese, John S., David Heckerman, and Carl Kadie. &quot;Empirical analysis of predictive algorithms for collaborative filtering.&quot; In Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence, pp. 43-52. Morgan Kaufmann Publishers Inc., 1998.</em> (<a href="http://dl.acm.org/citation.cfm?id=2074100">PDF</a>)</li>
<li><em>Zhang, Yi, Jamie Callan, and Thomas Minka. &quot;Novelty and redundancy detection in adaptive filtering.&quot; In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 81-88. ACM, 2002.</em> (<a href="http://dl.acm.org/citation.cfm?id=564393">PDF</a>)</li>
<li><em>Koren, Yehuda. &quot;Collaborative filtering with temporal dynamics.&quot; Communications of the ACM 53, no. 4 (2010): 89-97.</em> (<a href="http://dl.acm.org/citation.cfm?id=1721677">PDF</a>)</li>
<li><em>Rendle, Steffen, Christoph Freudenthaler, and Lars Schmidt-Thieme. &quot;Factorizing personalized markov chains for next-basket recommendation.&quot; In Proceedings of the 19th international conference on World wide web, pp. 811-820. ACM, 2010.</em> (<a href="http://dl.acm.org/citation.cfm?id=1772773">PDF</a>)</li>
<li><em>Sarwar, Badrul, George Karypis, Joseph Konstan, and John Riedl. &quot;Item-based collaborative filtering recommendation algorithms.&quot; In Proceedings of the 10th international conference on World Wide Web, pp. 285-295. ACM, 2001.</em> (<a href="http://dl.acm.org/citation.cfm?id=372071">PDF</a>)</li>
<li><em>Ma, Hao, Dengyong Zhou, Chao Liu, Michael R. Lyu, and Irwin King. &quot;Recommender systems with social regularization.&quot; In Proceedings of the fourth ACM international conference on Web search and data mining, pp. 287-296. ACM, 2011.</em> (<a href="http://dl.acm.org/citation.cfm?id=1935877">PDF</a>)</li>
<li><em>Herlocker, Jonathan L., Joseph A. Konstan, Loren G. Terveen, and John T. Riedl. &quot;Evaluating collaborative filtering recommender systems.&quot; ACM Transactions on Information Systems (TOIS) 22, no. 1 (2004): 5-53.</em> (<a href="http://dl.acm.org/citation.cfm?id=963772">PDF</a>)</li>
</ul></li>
<li><h3><strong>Day 4</strong>: Document visualization</h3>

<ul>
<li><em>Fortuna, Blaz, Dunja Mladeniƒá, and Marko Grobelnik. &quot;Visualization of text document corpus.&quot; (2005).</em> (<a href="http://eprints.pascal-network.org/archive/00001197/">PDF</a>)</li>
<li><em>Liu, Hugo, Ted Selker, and Henry Lieberman. &quot;Visualizing the affective structure of a text document.&quot; In CHI&#39;03 extended abstracts on Human factors in computing systems, pp. 740-741. ACM, 2003.</em> (<a href="http://dl.acm.org/citation.cfm?id=765961">PDF</a>)</li>
<li><em>Shiping, Huang, Matthew O. Ward, and Elke A. Rundensteiner. &quot;Exploration of dimensionality reduction for text visualization.&quot; In Coordinated and Multiple Views in Exploratory Visualization, 2005.(CMV 2005). Proceedings. Third International Conference on, pp. 63-74. IEEE, 2005.</em> (<a href="http://digitalcommons.wpi.edu/cgi/viewcontent.cgi?article=1139&amp;context=computerscience-pubs">PDF</a>)</li>
<li><em>Risch, John, Anne Kao, Stephen R. Poteet, and Y-J. Jason Wu. &quot;Text visualization for visual text analytics.&quot; In Visual data mining, pp. 154-171. Springer Berlin Heidelberg, 2008.</em> (<a href="http://link.springer.com/chapter/10.1007/978-3-540-71080-6_11#page-1">PDF</a>)</li>
<li><em>Cui, Weiwei, Yingcai Wu, Shixia Liu, Furu Wei, Michelle X. Zhou, and Huamin Qu. &quot;Context preserving dynamic word cloud visualization.&quot; In Pacific Visualization Symposium (PacificVis), 2010 IEEE, pp. 121-128. IEEE, 2010.</em> (<a href="http://research.microsoft.com/en-us/um/people/weiweicu/images/wordpv.pdf">PDF</a>)</li>
<li><em>Vi√©gas, Fernanda B., and Martin Wattenberg. &quot;Timelines tag clouds and the case for vernacular visualization.&quot; interactions 15, no. 4 (2008): 49-52.</em> (<a href="http://dl.acm.org/citation.cfm?id=1374501">PDF</a>)</li>
<li><em>Kaser, Owen, and Daniel Lemire. &quot;Tag-cloud drawing: Algorithms for cloud visualization.&quot; arXiv preprint cs/0703109 (2007).</em> (<a href="http://arxiv.org/pdf/cs.DS/0703109">PDF</a>)</li>
<li><em>Bateman, Scott, Carl Gutwin, and Miguel Nacenta. &quot;Seeing things in the clouds: the effect of visual features on tag cloud selections.&quot; In Proceedings of the nineteenth ACM conference on Hypertext and hypermedia, pp. 193-202. ACM, 2008.</em> (<a href="http://dl.acm.org/citation.cfm?id=1379130">PDF</a>)</li>
</ul></li>
</ul>

</div>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
